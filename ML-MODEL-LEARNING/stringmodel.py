"""Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JddBbUvhpm-Nb7IRLJWMCGpWm7R26Odc
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x
import tensorflow as tf

from tensorflow.keras import datasets, layers, models
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt
from keras.preprocessing.image import load_img
import numpy as np
from matplotlib import pyplot as plt
import pickle
from PIL import Image

"""

```
# This is formatted as code
```

# Setting up the Model
"""

instruments_data = tf.keras.utils.image_dataset_from_directory(
    r'C:\Users\alima\AppData\Local\Packages\CanonicalGroupLimited.UbuntuonWindows_79rhkp1fndgsc\LocalState\rootfs\home'
    r'\mashroor\capstone-Bsharp-AI\music_instruments_images\Strings', labels='inferred', batch_size=1,
    image_size=(128, 128))

train_images, train_labels = tuple(zip(*instruments_data))

train_images = np.array(train_images)
train_images = np.resize(train_images, (52368, 128, 128, 3))
train_labels = np.array(train_labels)
print(train_images)
print(train_labels)

train_images = train_images / 255.0

class_names = ['Trumpet', 'Tuba', 'Trombone', 'FrenchHorn']

# validation data#
validation_data = tf.keras.utils.image_dataset_from_directory(r'C:\Users\alima\AppData\Local\Packages'
                                                              r'\CanonicalGroupLimited.UbuntuonWindows_79rhkp1fndgsc'
                                                              r'\LocalState\rootfs\home\mashroor\capstone-Bsharp-AI'
                                                              r'\validation_images\Strings',
                                                              labels='inferred', batch_size=1, image_size=(128, 128))
val_images, val_labels = tuple(zip(*validation_data))

# validation images are the images to test the model on 
val_images = np.array(val_images)
val_images = np.resize(val_images, (2000, 128, 128, 3))
val_labels = np.array(val_labels)

print(val_images)
print(val_labels)
# print(val_images.shape)
val_images = val_images / 255.0

"""
IMG_INDEX = 150
plt.imshow(train_images[IMG_INDEX], cmap=plt.cm.binary)
plt.xlabel(class_names[train_labels[IMG_INDEX]])
plt.show()
"""

"""POOLING AND CONVOLUTION"""

model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))

# FLATTENING THE LAYERS

model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(5))

# TRAINING

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
history = model.fit(train_images, train_labels, epochs=5, validation_data=(val_images, val_labels))

pickle.dump(model, open('stringmodel.pkl', 'wb'))
